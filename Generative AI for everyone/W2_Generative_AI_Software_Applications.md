# Generative AI for Everyone

## Software Applications

This document summarizes how Generative AI is used in software
applications.

## 1. Prompt-Based Development

Traditional ML requires months of data collection and training.
Prompt-based AI allows rapid prototyping in minutes or hours.

## 2. Lifecycle of a Generative AI Project

1.  Scope project
2.  Build prototype
3.  Internal evaluation
4.  Deploy and monitor
5.  Improve iteratively

Generative AI development is highly empirical.

## 3. Improving Performance

-   Prompt engineering
-   Retrieval Augmented Generation (RAG)
-   Fine-tuning
-   Pretraining (rare and expensive)

## 4. Retrieval Augmented Generation (RAG)

RAG retrieves relevant documents and injects them into the prompt. This
reduces hallucinations and enables domain-specific Q&A.

## 5. Fine-Tuning

Fine-tuning adapts models to: - Specific style or structure - Domain
knowledge (medical, legal, financial) - Smaller model deployment

## 6. Choosing a Model

Model size affects reasoning ability: - Small models: basic pattern
matching - Large models: complex reasoning

Closed-source vs Open-source: - Closed: easy deployment, powerful -
Open: full control and privacy

## 7. Tool Use and Agents

LLMs can call external tools (e.g., calculators). Agents coordinate
multi-step reasoning workflows.

## 8. Cost Intuition

LLMs charge per token (≈ ¾ word per token). Costs scale with input +
output token usage.
